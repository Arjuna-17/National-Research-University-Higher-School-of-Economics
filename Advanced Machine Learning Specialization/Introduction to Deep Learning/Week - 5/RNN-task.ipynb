{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13d709b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 55\n"
     ]
    }
   ],
   "source": [
    "tokens = set(''.join(names[:]))\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id = {}\n",
    "for i in range(n_tokens):\n",
    "    token_to_id[tokens[i]] = i\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[37 40  3 39 30 39 41 23  0]\n",
      " [37  0 23 32 48  4  0  0  0]\n",
      " [37 51 48 42  2  2 42 41  0]\n",
      " [37  0 42 32 21 39 50 50 41]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='relu')\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f139c6d2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FydeuGGGGGGGGGG\n",
      " AnnararlaGGGGGG\n",
      " RhdyGGGGGGGGGGG\n",
      " RemecyGGGGGGGGG\n",
      " EbisGGGGGGGGGGG\n",
      " DephneGGGGGGGGG\n",
      " EthehGGGGGGGGGG\n",
      " ranteGGGGGGGGGG\n",
      " KaeraGGGGGGGGGG\n",
      " AascafGGGGGGGGG\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TrumpyndGGGGGGG\n",
      " TrumpoGGGGGGGGG\n",
      " TrumphaGGGGGGGG\n",
      " TrumphonGGGGGGG\n",
      " TrumponhGGGGGGG\n",
      " TrumpigGGGGGGGG\n",
      " TrumpoGGGGGGGGG\n",
      " TrumpicepleGGGG\n",
      " TrumpialGGGGGGG\n",
      " TrumpasGGGGGGGG\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"sDlEKKpfVmvqRpRw\"\n",
    "COURSERA_EMAIL = \"v.s.sandeep.pasumarthi@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ad05430219464b87e66c80187c5954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 55)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
